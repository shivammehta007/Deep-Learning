{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OSp18hvBgSg",
        "colab_type": "text"
      },
      "source": [
        "* Read Language model tutorial ---> https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275\n",
        "* Find one english corpus with poetries in the internet (e.g from here) --> https://www.poetryfoundation.org/poems\n",
        "* You can use whatever corpus you want (e.g. your favorite book)\n",
        "* Encapsulate LSTM building like MLP from the first task\n",
        "* Train LSTM as language model on your corpus like in the tutorial\n",
        "* Also, you need to compare 1-layer and 2-layer LSTMs\n",
        "* Compare texts, generated by your models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3rdTupmBgSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import adam, adagrad, adadelta, rmsprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import L1L2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import ParameterGrid, train_test_split\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L38QIwIECiM1",
        "colab_type": "code",
        "outputId": "e1a13659-f81a-45ac-f625-66ad46c7e52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KXJ2f9jBgSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read Data\n",
        "folder_name = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "filename = os.path.join(folder_name, 'task3_corpus.csv')\n",
        "# filename = 'task3_corpus.csv'\n",
        "file_type = 'csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fW7IwapBgS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(filename, file_type):\n",
        "    if file_type == 'csv':\n",
        "        data = pd.read_csv(filename)\n",
        "        data = data['text']\n",
        "        \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwGWpRi_BgTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = read_data(filename, file_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDLP6YnyBgUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = '\\n'.join([row for row in df])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REwgMEzJBgUU",
        "colab_type": "code",
        "outputId": "9540e057-9234-4efe-9034-ae937acfcad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "layers = [( 'LSTM', 150), ('Dropout', 0.2), ('LSTM', 120)]\n",
        "count = [x for x,_ in layers].count('LSTM')\n",
        "print(count)\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Z8RQoVBgUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelFormer:\n",
        "    def __init__(self):\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.best_model = Sequential()\n",
        "        self.best_accuracy = 0\n",
        "        self.best_parameters = {}\n",
        "        \n",
        "    def fit_data(self, text):\n",
        "        self.original_corpus = text\n",
        "        self.corpus = self.original_corpus.lower().split('\\n')\n",
        "        self.tokenizer.fit_on_texts(self.corpus)\n",
        "        self.word_count = len(self.tokenizer.word_index) + 1\n",
        "        input_sequences = []\n",
        "        for line in self.corpus:\n",
        "            tokens = self.tokenizer.texts_to_sequences([line])[0]\n",
        "            for i in range(1, len(tokens)):\n",
        "                n_grams_sequence = tokens[:i+1]\n",
        "                input_sequences.append(n_grams_sequence)\n",
        "        \n",
        "        input_sequences = self.pad_input_sequences(input_sequences)\n",
        "        \n",
        "        x_data, y_data = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "        y_data = np_utils.to_categorical(y_data, num_classes=self.word_count)\n",
        "        \n",
        "        return x_data, y_data\n",
        "              \n",
        "    def pad_input_sequences(self,input_sequences):\n",
        "        max_sequence_length = max([len(sentence) for sentence in input_sequences])\n",
        "        input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))\n",
        "        return input_sequences\n",
        "    \n",
        "    def fit(self, x_data, y_data , layers= [( 'LSTM', 150), ('Dropout', 0.2), ('LSTM', 120)], activation='tanh', optimizer='adam', lr=0.01, epochs=20):\n",
        "        self.model = Sequential()\n",
        "        \n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        x_train, x_val, y_train, y_val = train_test_split(self.x_data, self.y_data)\n",
        "        \n",
        "        \n",
        "        self.model.add(Embedding(self.word_count, 10, input_length=len(x_data[0]) ))\n",
        "        count_lstm_retn_flag = [x for x,_ in layers].count('LSTM') - 1\n",
        "\n",
        "        for layer,value in layers:\n",
        "            if layer == 'LSTM':\n",
        "                if count_lstm_retn_flag:\n",
        "                    count_lstm_retn_flag -= 1\n",
        "                    return_sequences = True \n",
        "                else:\n",
        "                    return_sequences = False\n",
        "                self.model.add(LSTM(value, activation=activation, return_sequences=return_sequences))\n",
        "            if layer == 'Dropout':\n",
        "                self.model.add(Dropout(value))\n",
        "        \n",
        "        self.model.add(Dense(self.word_count, activation='softmax'))\n",
        "        if optimizer == 'adam':\n",
        "            optimizer = adam(lr=lr)\n",
        "        elif optimizer == 'adadelta':\n",
        "            optimizer = adadelta(lr=lr)\n",
        "        elif optimizer == 'rmsprop':\n",
        "            optimizer = rmsprop(lr=lr)\n",
        "            \n",
        "            \n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        self.model.summary()\n",
        "        \n",
        "        fit_summary = self.model.fit(x_train, y_train, epochs=epochs, verbose=1, validation_data=(x_val, y_val), batch_size=20)\n",
        "        if fit_summary.history['acc'][-1] > self.best_accuracy:\n",
        "            self.best_model = self.model\n",
        "            self.best_accuracy = fit_summary.history['acc'][-1]\n",
        "            self.best_parameters = (layers, activation, optimizer, lr, epochs)\n",
        "        \n",
        "        return fit_summary\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um7C_bMBBgUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = ModelFormer()\n",
        "X, Y= m.fit_data(text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxxUqsczBgU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train , x_test, y_train, y_test = train_test_split(X,Y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEvPZQedBgVA",
        "colab_type": "code",
        "outputId": "e1f1e726-08a0-4b7d-fcc8-432955c1353e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(x_train), len(y_train), len(x_test), len(y_test))"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8847 8847 3792 3792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMKPolLxBgWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Grid Search with Parameter Grid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOAkMxdABgWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameters = { 'layers': [ [( 'LSTM', 200), ('Dropout', 0.2)], [( 'LSTM', 200), ('Dropout', 0.2), ('LSTM', 400), ('Dropout', 0.2) ]], \n",
        "                     'activation': ['tanh'],\n",
        "                     'optimizer' : [ ('adam', 0.01 ), ('adam', 0.001 ) , ('adadelta', 1 ), ('rmsprop', 0.1 )],\n",
        "                     'epochs' : [50]\n",
        "                   }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unOtt-QJBgWn",
        "colab_type": "code",
        "outputId": "ef06ce53-9d57-4a3b-98bc-efa4dab3c5e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "combinations = list(ParameterGrid(hyperparameters))\n",
        "combinations"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'activation': 'tanh',\n",
              "  'epochs': 50,\n",
              "  'layers': [('LSTM', 200), ('Dropout', 0.2)],\n",
              "  'optimizer': ('adam', 0.01)},\n",
              " {'activation': 'tanh',\n",
              "  'epochs': 50,\n",
              "  'layers': [('LSTM', 200), ('Dropout', 0.2)],\n",
              "  'optimizer': ('adam', 0.001)},\n",
              " {'activation': 'tanh',\n",
              "  'epochs': 50,\n",
              "  'layers': [('LSTM', 200), ('Dropout', 0.2)],\n",
              "  'optimizer': ('adadelta', 1)},\n",
              " {'activation': 'tanh',\n",
              "  'epochs': 50,\n",
              "  'layers': [('LSTM', 200), ('Dropout', 0.2)],\n",
              "  'optimizer': ('rmsprop', 0.1)},\n",
              " {'activation': 'tanh',\n",
              "  'epochs': 50,\n",
              "  'layers': [('LSTM', 200), ('Dropout', 0.2), ('LSTM', 400), ('Dropout', 0.2)],\n",
              "  'optimizer': ('adam', 0.01)},\n",
              " {'activation': 'tanh',\n",
              "  'epochs': 50,\n",
              "  'layers': [('LSTM', 200), ('Dropout', 0.2), ('LSTM', 400), ('Dropout', 0.2)],\n",
              "  'optimizer': ('adam', 0.001)},\n",
              " {'activation': 'tanh',\n",
              "  'epochs': 50,\n",
              "  'layers': [('LSTM', 200), ('Dropout', 0.2), ('LSTM', 400), ('Dropout', 0.2)],\n",
              "  'optimizer': ('adadelta', 1)},\n",
              " {'activation': 'tanh',\n",
              "  'epochs': 50,\n",
              "  'layers': [('LSTM', 200), ('Dropout', 0.2), ('LSTM', 400), ('Dropout', 0.2)],\n",
              "  'optimizer': ('rmsprop', 0.1)}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmkHhKE0WiQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit_summary_array = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EApzDLTlXP5s",
        "colab_type": "code",
        "outputId": "97a43bab-6896-4211-cc33-cee1cba02e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "for combination in combinations:\n",
        "    print('Current Combination : {}'.format(combination))\n",
        "    m.fit(x_train, y_train, layers=combination['layers'], activation=combination['activation'], optimizer=combination['optimizer'][0], lr=combination['optimizer'][1], epochs=combination['epochs'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Combination : {'activation': 'tanh', 'epochs': 50, 'layers': [('LSTM', 200), ('Dropout', 0.2)], 'optimizer': ('adam', 0.01)}\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_31 (Embedding)     (None, 54, 10)            21850     \n",
            "_________________________________________________________________\n",
            "lstm_44 (LSTM)               (None, 200)               168800    \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 2185)              439185    \n",
            "=================================================================\n",
            "Total params: 629,835\n",
            "Trainable params: 629,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 6635 samples, validate on 2212 samples\n",
            "Epoch 1/50\n",
            "6635/6635 [==============================] - 41s 6ms/step - loss: 6.5067 - acc: 0.0524 - val_loss: 6.3879 - val_acc: 0.0633\n",
            "Epoch 2/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 5.9444 - acc: 0.0735 - val_loss: 6.3883 - val_acc: 0.0999\n",
            "Epoch 3/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 5.4277 - acc: 0.1177 - val_loss: 6.3533 - val_acc: 0.1171\n",
            "Epoch 4/50\n",
            "6635/6635 [==============================] - 32s 5ms/step - loss: 4.7358 - acc: 0.1604 - val_loss: 6.4929 - val_acc: 0.1307\n",
            "Epoch 5/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 4.0957 - acc: 0.2075 - val_loss: 6.6824 - val_acc: 0.1329\n",
            "Epoch 6/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 3.4244 - acc: 0.2695 - val_loss: 7.0416 - val_acc: 0.1379\n",
            "Epoch 7/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 2.8250 - acc: 0.3595 - val_loss: 7.3537 - val_acc: 0.1388\n",
            "Epoch 8/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 2.3045 - acc: 0.4482 - val_loss: 7.6044 - val_acc: 0.1420\n",
            "Epoch 9/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 1.9381 - acc: 0.5260 - val_loss: 7.8872 - val_acc: 0.1361\n",
            "Epoch 10/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 1.6316 - acc: 0.5797 - val_loss: 8.1105 - val_acc: 0.1388\n",
            "Epoch 11/50\n",
            "6635/6635 [==============================] - 32s 5ms/step - loss: 1.4227 - acc: 0.6291 - val_loss: 8.2989 - val_acc: 0.1410\n",
            "Epoch 12/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 1.2482 - acc: 0.6722 - val_loss: 8.4760 - val_acc: 0.1379\n",
            "Epoch 13/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 1.1541 - acc: 0.6910 - val_loss: 8.6765 - val_acc: 0.1352\n",
            "Epoch 14/50\n",
            "6635/6635 [==============================] - 31s 5ms/step - loss: 1.1469 - acc: 0.6885 - val_loss: 8.7102 - val_acc: 0.1433\n",
            "Epoch 15/50\n",
            "2460/6635 [==========>...................] - ETA: 17s - loss: 0.9174 - acc: 0.7496"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXTfa8M0X3V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.best_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh3f1aZe0YWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}